

1. pipline 里需要return item 以便多个pipline处理item
2. 获取数据的时候记录comeFrom
3. hr.py  parse 里面重新 根据下一页创造request
4. yield scrapy.Request(next_url,callback=self.parse)
5. yield 发送到引擎
6. meta 解析函数间传递数据 ，放在response里
7. dont_filter=false 默认请求过的不再请求
8. item 和 dict 都可以yield
9. follow应该要写  请求的页面是否经过这个规则 
10. yield scrapy.Request(url,callback=self.parse_detail,meta={"item":item})
11. rule 之间不能传递请求，但是手动的可以

12. 这边写个规则，那边写个解析这样不好

13. ```js
    attribute = Attribute(attribute_json)
    ```

    规范json 写法

14. ```js
    cb_res
    ```

用于透传数据





```
 {
  "allow": "",
  "restrict_xpaths": "//*[@id=\"root\"]/main/div//div/div[@class=\"Pager fr\"]/a[last()]",
  "callback": ""
},
```